Healthcare Twitter Analytics
========================================================
## Basic Text Mining
```{r,echo=FALSE}
dir = 'C:/Users/GRFisher4/Documents/Introduction_to_Data_Science/Healthcare_Twitter_Analysis/healthcare_twitter_analysis'
setwd(dir)
# see http://jeffreybreen.wordpress.com/2011/07/04/twitter-text-mining-r-slides/

 
rm(list = setdiff(ls(), lsf.str())) # remove all but functions
opar = par(no.readonly=TRUE)
```

```{r,message=FALSE}
file = 'Tweets_Celiac_sent.csv'
data = read.csv(file,colClasses = "character")
text = data$content
rm(data)
```
###Load the corpus and do basic transforms
```{r,message=FALSE}
library(tm)
in_corpus = VCorpus(VectorSource(text))

tx_corpus = tm_map(in_corpus, stripWhitespace)
tx_corpus = tm_map(tx_corpus, content_transformer(tolower))
tx_corpus = tm_map(tx_corpus, removeWords, stopwords("english"))
#tx_corpus = tm_map(tx_corpus, removePunctuation)
tx_corpus = tm_map(tx_corpus, stemDocument)

inspect(in_corpus[1])   # before transformation
inspect(tx_corpus[1])   # after transformation
```
###Word Cloud
```{r,message=FALSE,warning=FALSE}
library(wordcloud)

tdm = TermDocumentMatrix(
  in_corpus,
  control = list(
    removePunctuation = TRUE,
    stopwords = c(stopwords("english")),
    removeNumbers = TRUE, tolower = TRUE)
    )
 
m = as.matrix(tdm)
# get word counts in decreasing order
word_freqs = sort(rowSums(m), decreasing = TRUE) 
# create a data frame with words and their frequencies
dm = data.frame(word = names(word_freqs), freq = word_freqs)
wordcloud(dm$word, dm$freq, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
```    
  
###Create reduced term matrices  
```{r}
dterm_mat <- DocumentTermMatrix(tx_corpus)
dterm_mat <- removeSparseTerms(dterm_mat, 0.95)
inspect(dterm_mat[1:10,])

tterm_mat <- TermDocumentMatrix(tx_corpus)
tterm_mat <- removeSparseTerms(tterm_mat, 0.95)
inspect(tterm_mat[,1:10])
```
###Find term frequencies
```{r}
findFreqTerms(dterm_mat, 100)  # at least 100 occurences
```
###Find correlation to "celiac"
```{r}
findAssocs(dterm_mat, "celiac", 0.7) # 70% correlation
```
###Agglomerative Hierarchical Dendogram
```{r}
# this thing insists on listing its entire contents
#bagofwords = as.data.frame(inspect(tterm_mat))
#saveRDS(bagofwords, file="bagofwords.rds")
bagofwords = readRDS("bagofwords.rds")

bagofwords.scale = scale(bagofwords)
d = dist(bagofwords.scale, method = "euclidean") # distance matrix
fit = hclust(d, method="ward.D")
plot(fit) # display dendogram?

num_clusters = 6
groups = cutree(fit, k=num_clusters) 
# draw dendogram with red borders around the clusters
rect.hclust(fit, k=num_clusters, border="red")
```
